---
title: "평가/기록"
description: "평가/비교/기록 방식"
---
## 이 문서에서 하는 것
- 같은 질문을 여러 설정으로 실행해서 결과/비용/속도를 비교해.

## 준비물
- Practice 세션(새로 만들거나 기존 세션)
- 모델 1개 선택

## 조절 변수(핵심)
- 모델: provider/model_name
- 파라미터: temperature, top_p, max_tokens (및 response length preset을 쓰면 같이)
- (선택) Agents: system prompt + few-shot 예시
- (선택) RAG: top-k/threshold/rerank

## 기록할 지표
- 지연시간(latency) / TTFT
- 토큰(prompt/completion/total)
- 비용(추정치)
- 품질(정확도/가독성/근거성)

## 자주 터지는 실수
- 변수를 한 번에 여러 개 바꿈(원인 분석 불가)
- few-shot이 너무 김(비용/지연 급증)
- temperature 과다(사실 QA에서 환각 위험)

## 평가 루브릭(예시)
- 정확도(0~5)
- 근거성/출처 적합성(0~5)
- 구조/가독성(0~5)
- 안전/정책 준수(0~5)

## 공정 비교 팁
- 변수 1개만 바꾸기
- 질문 세트 고정
- 지표는 자동 기록되게(가능하면)

## 다음 문서
- /tutorials/05-ab-compare

